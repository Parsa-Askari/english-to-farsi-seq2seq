{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c6369c-abc1-424c-bd75-81f1c7c06d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 17:28:46.612629: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-13 17:28:46.694325: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-13 17:28:46.694430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-13 17:28:46.694466: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-13 17:28:46.707028: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 17:28:48.512901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import hazm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as eng_tokenize\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4abf63d0-695e-4bb0-b874-ff25da281ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self,en_data,fa_data,en_index,fa_index):\n",
    "        super(dataset,self).__init__()\n",
    "        for seq in en_data:\n",
    "            for i in range(len(seq)):\n",
    "                seq[i]=en_index[seq[i]]\n",
    "        for seq in fa_data:\n",
    "            for i in range(len(seq)):\n",
    "                seq[i]=fa_index[seq[i]]\n",
    "        self.en_data=torch.from_numpy(pad_sequences(en_data,padding=\"post\",maxlen=10,value=1))\n",
    "        self.fa_data=torch.from_numpy(pad_sequences(fa_data,padding=\"post\",maxlen=10,value=1))\n",
    "        self.fa_data=torch.concat((torch.zeros(len(self.fa_data),1),self.fa_data),dim=1).long()\n",
    "    def __len__(self):\n",
    "        return len(self.en_data)\n",
    "    def __getitem__(self,idx):\n",
    "        return self.en_data[idx],self.fa_data[idx][:-1],self.fa_data[idx][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6417f4a-51aa-4656-9d7e-b6575499abf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./hugg_preprocessed/vocab_en\", \"rb\") as fp:   # Unpickling\n",
    "    vocab_en = pickle.load(fp)\n",
    "with open(\"./hugg_preprocessed/vocab_fa\", \"rb\") as fp:   # Unpickling\n",
    "    vocab_fa = pickle.load(fp)\n",
    "with open(\"./hugg_preprocessed/dataset_en\", \"rb\") as fp:   # Unpickling\n",
    "    dataset_en = pickle.load(fp)\n",
    "with open(\"./hugg_preprocessed/dataset_fa\", \"rb\") as fp:   # Unpickling\n",
    "    dataset_fa = pickle.load(fp)\n",
    "with open(\"./hugg_preprocessed/en_index.json\", \"r\") as fp:   #Pickling\n",
    "    en_index=json.load(fp)\n",
    "with open(\"./hugg_preprocessed/fa_index.json\", \"r\") as fp:   #Pickling\n",
    "    fa_index=json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1d5ae74-9361-44ed-b731-cbb91ef29953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CELL(nn.Module):\n",
    "    def __init__(self,hidden_size,embeding_size):\n",
    "        super(CELL,self).__init__()\n",
    "        # self.input_net=nn.Embedding(num_embeddings=len(vocab),embedding_dim=embeding_dim)\n",
    "        \n",
    "        self.WF=nn.Parameter(torch.rand(hidden_size+embeding_size,hidden_size),requires_grad=True)\n",
    "        self.BF=nn.Parameter(torch.rand(1,hidden_size),requires_grad=True)\n",
    "        self.sigF=nn.Sigmoid()\n",
    "        \n",
    "        self.WI1=nn.Parameter(torch.rand(hidden_size+embeding_size,hidden_size),requires_grad=True)\n",
    "        self.BI1=nn.Parameter(torch.rand(1,hidden_size),requires_grad=True)\n",
    "        self.sigI=nn.Sigmoid()\n",
    "        self.WI2=nn.Parameter(torch.rand(hidden_size+embeding_size,hidden_size),requires_grad=True)\n",
    "        self.BI2=nn.Parameter(torch.rand(1,hidden_size),requires_grad=True)\n",
    "        self.tanhI=nn.Tanh()\n",
    "        \n",
    "        self.WO=nn.Parameter(torch.rand(hidden_size+embeding_size,hidden_size),requires_grad=True)\n",
    "        self.BO=nn.Parameter(torch.rand(1,hidden_size),requires_grad=True)\n",
    "        self.tanhO=nn.Tanh()\n",
    "        self.sigO=nn.Sigmoid()\n",
    "    \n",
    "    def forward(self,x_batch,short_memory,long_memory):\n",
    "        \"\"\"\n",
    "        x_batch = (batch_size,embeding_size)\n",
    "        short_memory =(batch_size,hidden_size)\n",
    "        long_memory =(batch_size,hidden_size)\n",
    "        \"\"\"\n",
    "        # emb_batch=self.input_net(x_batch)\n",
    "        emb_batch=x_batch\n",
    "        scaler=emb_batch.shape[0]\n",
    "        #Forget gate\n",
    "        new_batch=torch.concat((short_memory,emb_batch),dim=1) #(batch_size,hidden_size+embeding_size)\n",
    "        zF=torch.matmul(new_batch,self.WF) +self.BF #batch_size,hidden_size\n",
    "        aF=self.sigF(zF)\n",
    "        \n",
    "        #Input gate\n",
    "        zI1=torch.matmul(new_batch,self.WI1) + self.BI1 #batch_size,hidden_size\n",
    "        aI1=self.sigI(zI1)\n",
    "        \n",
    "        zI2=torch.matmul(new_batch,self.WI2) +self.BI2 #batch_size,hidden_size\n",
    "        aI2=self.tanhI(zI2)\n",
    "        aI=aI1*aI2\n",
    "        \n",
    "        #Output gate\n",
    "        long_memory=(long_memory*aF)+(long_memory+aI) #batch_size,hidden_size\n",
    "        \n",
    "        zO1=torch.matmul(new_batch,self.WO) +self.BO #batch_size,hidden_size\n",
    "        aO1=self.sigO(zO1)\n",
    "        \n",
    "        aO2=self.tanhO(long_memory)\n",
    "        \n",
    "        short_memory=aO1*aO2\n",
    "        \n",
    "        return short_memory,long_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc7a5ca7-c431-4f7b-b155-952b608ffd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self,layer_num,hidden_size,embeding_size):\n",
    "        super(LSTM,self).__init__()\n",
    "        layers=[]\n",
    "        for i in range(layer_num):\n",
    "            layers.append(CELL(hidden_size,embeding_size))\n",
    "            layers.append(nn.Linear(in_features=hidden_size,out_features=embeding_size))\n",
    "        self.Pipeline=nn.ParameterList(layers[:-1])\n",
    "    def forward(self,x,memory_cache):\n",
    "        new_memory_cache=[]\n",
    "        for i,l in enumerate(self.Pipeline):\n",
    "            if((i+1)%2!=0):\n",
    "                h,c=memory_cache[i//2][0],memory_cache[i//2][1]\n",
    "                h_new,c_new=self.Pipeline[i](x,h,c)\n",
    "                new_memory_cache.append([h_new,c_new])\n",
    "                x=h\n",
    "            else:\n",
    "                x=self.Pipeline[i](x)\n",
    "        return new_memory_cache,x\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,layer_num,hidden_size,embeding_dim,vocab_size):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.embeding_layer=nn.Embedding(num_embeddings=vocab_size,embedding_dim=embeding_dim)\n",
    "        self.lstm=LSTM(layer_num,hidden_size,embeding_dim)\n",
    "    def forward(self,memory_cache,x_batch):\n",
    "        \"\"\"\n",
    "        x_batch shape =(batch_size,) input batch of english words\n",
    "        memory_cache shape = (layer_num,2) its a 2D list contains [h,c] \n",
    "        \"\"\"\n",
    "        embeded_batch=self.embeding_layer(x_batch)\n",
    "        new_memory_cache , _=self.lstm(embeded_batch,memory_cache)\n",
    "        return new_memory_cache\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,layer_num,hidden_size,embeding_dim,vocab_size):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.embeding_layer=nn.Embedding(num_embeddings=vocab_size,embedding_dim=embeding_dim)\n",
    "        self.lstm=LSTM(layer_num,hidden_size,embeding_dim)\n",
    "        self.linear=nn.Linear(hidden_size,vocab_size)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "    def forward(self,memory_cache,x_batch):\n",
    "        \"\"\"\n",
    "        x_batch shape =(batch_size,) input batch of english words\n",
    "        memory_cache shape = (layer_num,2) its a 2D list contains [h,c] \n",
    "        \"\"\"\n",
    "        embeded_batch=self.embeding_layer(x_batch)\n",
    "        new_memory_cache , x=self.lstm(embeded_batch,memory_cache)\n",
    "        x=self.linear(x)\n",
    "        x=self.softmax(x)\n",
    "        return new_memory_cache , x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23d572ff-743e-4522-be4d-10aee7b16c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_memory(batch_size,hidden_size,layer_num):\n",
    "    mem_list=[]\n",
    "    for i in range(layer_num):\n",
    "        mem_list.append([torch.zeros(batch_size,hidden_size),torch.zeros(batch_size,hidden_size)])\n",
    "    return mem_list\n",
    "def detach_memory(memory_cache):\n",
    "    for i in len(memory_cache):\n",
    "        memory_cache[i][0]=memory_cache[i][0].detach()\n",
    "        memory_cache[i][1]=memory_cache[i][1].detach()\n",
    "    return memory_cache\n",
    "def Train(TrainLoader,batch_size,epochs,encoder,decoder,encoder_config,decoder_config,EncoderOptimizer,DecoderOptimizer,loss_fn):\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        for en,fa,fa_target in tqdm(TrainLoader):\n",
    "            memory_cache=reset_memory(batch_size=en.shape[0],\n",
    "                                  hidden_size=encoder_config[\"hidden_size\"],\n",
    "                                  layer_num=encoder_config[\"layers_num\"])\n",
    "\n",
    "            # Encoder\n",
    "            \n",
    "            seq_length=en.shape[1]\n",
    "            for i in range(seq_length):\n",
    "                x_batch=en[:,i]\n",
    "                new_memory_cache=encoder(memory_cache,x_batch)\n",
    "                memory_cache=new_memory_cache\n",
    "\n",
    "            # Decoder\n",
    "            \n",
    "            seq_length=fa.shape[1]\n",
    "            loss=0\n",
    "            for i in range(seq_length):\n",
    "                x_batch=fa[:,i]\n",
    "                y_batch=fa_target[:,i]\n",
    "                new_memory_cache,y_pred=decoder(memory_cache,x_batch)\n",
    "                loss+=loss_fn(input=y_pred,target=y_batch.reshape(-1))\n",
    "            loss=loss/batch_size\n",
    "            loss.backward()\n",
    "            EncoderOptimizer.step()\n",
    "            DecoderOptimizer.step()\n",
    "            EncoderOptimizer.zero_grad()\n",
    "            DecoderOptimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ed4c0c0-d0c3-4a8f-9271-28533e175cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_size=256\n",
    "embeding_dim=1\n",
    "batch_size=32\n",
    "layer_number=4\n",
    "en_vocab_size=len(vocab_en)\n",
    "fa_vocab_size=len(vocab_fa)\n",
    "epochs=100\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf076740-e04f-4167-83c1-9872a4228e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds=dataset(dataset_en,dataset_fa,en_index,fa_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97fd448f-dd98-42a0-95e2-f5aaf761df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader=DataLoader(ds,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efd592-95a6-4a68-8fd9-02a663347658",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_config={\"layers_num\":2,\"hidden_size\":256,\"embeding_size\":100}\n",
    "decoder_config={\"layers_num\":2,\"hidden_size\":256,\"embeding_size\":100}\n",
    "\n",
    "encoder=Encoder(encoder_config[\"layers_num\"],encoder_config[\"hidden_size\"],encoder_config[\"embeding_size\"],vocab_size=en_vocab_size)\n",
    "decoder=Decoder(decoder_config[\"layers_num\"],decoder_config[\"hidden_size\"],decoder_config[\"embeding_size\"],vocab_size=fa_vocab_size)\n",
    "EncoderOptimizer=torch.optim.Adam(lr=0.0001,params=encoder.parameters()).to(de)\n",
    "DecoderOptimizer=torch.optim.Adam(lr=0.0001,params=decoder.parameters())\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "Train(TrainLoader=trainLoader,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      encoder=encoder,\n",
    "      decoder=decoder,\n",
    "      encoder_config=encoder_config,\n",
    "      decoder_config=decoder_config,\n",
    "      EncoderOptimizer=EncoderOptimizer,\n",
    "      DecoderOptimizer=DecoderOptimizer,\n",
    "      loss_fn=loss_fn\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4470636b-633d-4065-b95f-d53d906b365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1=LSTM(1,2,3)\n",
    "lstm2=LSTM(1,2,3)\n",
    "oprtimizer=torch.optim.Adam(params=[\n",
    "    {'params': lstm1.parameters()},\n",
    "    {'params': lstm2.parameters()}\n",
    "],lr=0.0001)\n",
    "# lstm1.parameters()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
