{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b4a7985-a318-4a89-be50-dcacc095d018",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hazm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as eng_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "# nltk.download('punkt');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baa34ed4-4e14-4d92-b226-f444618d1210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "farsi_path=\"./PEPC_Bidirectional/wiki_extracted_200k.fa\"\n",
    "english_path=\"./PEPC_Bidirectional/wiki_extracted_200k.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece5bf59-1736-493f-a25e-02a6f0e9846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess:\n",
    "    def __init__(self):\n",
    "        self.vocab_fa=[]\n",
    "        self.vocab_en=[]\n",
    "        self.dataset_en=[]\n",
    "        self.dataset_fa=[]\n",
    "        self.EOS=\"_EOS_\"\n",
    "    def ReadCorpus(self,farsi_path,english_path):\n",
    "        with open(farsi_path,\"r\") as f:\n",
    "            self.farsi_corpus=f.readlines()\n",
    "        with open(english_path,\"r\") as f:\n",
    "            self.english_corpus=f.readlines()\n",
    "    def Tokenize(self):\n",
    "        for i in tqdm(range(len(self.english_corpus))):\n",
    "            en_tokenized=eng_tokenize(self.english_corpus[i])\n",
    "            fa_tokenized=word_tokenize(self.farsi_corpus[i])\n",
    "            en_tokenized.append(self.EOS)\n",
    "            fa_tokenized.append(self.EOS)\n",
    "            self.dataset_en.append(en_tokenized)\n",
    "            self.dataset_fa.append(fa_tokenized)\n",
    "            self.vocab_en+=en_tokenized\n",
    "            self.vocab_fa+=fa_tokenized\n",
    "    def DeleteNumbers(self):\n",
    "        pass\n",
    "    def DeleteEmojis(self):\n",
    "        pass\n",
    "    def Transfrom(self,en_path,fa_path,del_emoji=False,del_numbers=False):\n",
    "        self.ReadCorpus(fa_path,en_path)\n",
    "        self.Tokenize()\n",
    "        return list(set(self.vocab_en)),list(set(self.vocab_fa)),self.dataset_en,self.dataset_fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753664de-231e-4217-ae29-b0c4abe17f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75321004b01e46329640ad0b3096f621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199936 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prep=preprocess()\n",
    "vocab_en,vocab_fa,dataset_en,dataset_fa=prep.Transfrom(en_path=english_path,fa_path=farsi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0cab2c-5c1c-45ac-b181-f0fa97eca103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
