{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54bfe576-d62e-492a-a500-ef0ce748045d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hazm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hazm import word_tokenize,Normalizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as eng_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a26fd7b-6466-4b2f-a02a-d607630c060e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(iter(imdb_dataset))[\"translation\"]\n",
    "dataset=load_dataset(\"tep_en_fa_para\")[\"train\"][\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c68205cf-f32d-4303-9398-d7c19bbaa9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(farsi_s,eng_s):\n",
    "    farsi_s=farsi_s.lower()\n",
    "    farsi_s=re.sub(r\",+\",\" , \",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\.+\",\" . \",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\_+\",\" _ \",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\$\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"#\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"=\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"@\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\d\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"~\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\'\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\">\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"<\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\+\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\-\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\/\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\*\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\\"\",\"\",farsi_s)\n",
    "    farsi_s=re.sub(r\"\\â€¦+\",\" \",farsi_s)\n",
    "\n",
    "    eng_s=eng_s.lower()\n",
    "    eng_s=re.sub(r\",+\",\" , \",eng_s)\n",
    "    eng_s=re.sub(r\"\\.+\",\" . \",eng_s)\n",
    "    eng_s=re.sub(r\"\\_+\",\" _ \",eng_s)\n",
    "    eng_s=re.sub(r\"\\$\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"#\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"=\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"@\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\d\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"~\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\'\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\">\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"<\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\+\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\-\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\/\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\*\",\"\",eng_s)\n",
    "    eng_s=re.sub(r\"\\\"\",\"\",eng_s)\n",
    "    return farsi_s,eng_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8530b72-170e-46ab-826c-61fcec65de77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51180befc1b24979817b9a3200e97e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/612087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_en=[]\n",
    "dataset_fa=[]\n",
    "vocab_en=[]\n",
    "vocab_fa=[]\n",
    "Max_input_size=10\n",
    "normalizer = Normalizer()\n",
    "for dic in tqdm(dataset):\n",
    "    farsi_s=dic[\"fa\"]\n",
    "    eng_s=dic[\"en\"]\n",
    "    farsi_s,eng_s=clean(farsi_s,eng_s)\n",
    "    eng_tokenized=eng_tokenize(eng_s)\n",
    "    fa_tokenized=word_tokenize(normalizer.normalize(farsi_s))\n",
    "    if(len(eng_tokenized)>=10 or len(fa_tokenized)>=10):\n",
    "        continue\n",
    "    dataset_en.append(eng_tokenized+[\"_EOS_\"])\n",
    "    dataset_fa.append(fa_tokenized+[\"_EOS_\"])\n",
    "    vocab_en+=eng_tokenized\n",
    "    vocab_fa+=fa_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c1be20-951d-4f38-9f1c-2193f38bd203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_en=[\"_EOS_\",\"_PAD_\"]+list(set(vocab_en))\n",
    "vocab_fa=[\"_EOS_\",\"_PAD_\"]+list(set(vocab_fa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fb12c7-d7bf-4684-8054-b5778a5e165e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8626655910544bbdba6d2fef8087559a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77363ae350754175a13a6641ac10637b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_index={}\n",
    "fa_index={}\n",
    "for i,token in tqdm(enumerate(vocab_en)):\n",
    "    en_index[token]=i\n",
    "for i,token in tqdm(enumerate(vocab_fa)):\n",
    "    fa_index[token]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936c4043-309a-40fe-8080-9a7fe3c6346e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./hugg_preprocessed/en_index.json\", \"w\") as outfile: \n",
    "    json.dump(en_index, outfile)\n",
    "with open(\"./hugg_preprocessed/fa_index.json\", \"w\") as outfile: \n",
    "    json.dump(fa_index, outfile)\n",
    "with open(\"./hugg_preprocessed/vocab_en\", \"wb\") as fp:   \n",
    "    pickle.dump(vocab_en, fp)\n",
    "with open(\"./hugg_preprocessed/vocab_fa\", \"wb\") as fp:  \n",
    "    pickle.dump(vocab_fa, fp)\n",
    "with open(\"./hugg_preprocessed/dataset_en\", \"wb\") as fp:   \n",
    "    pickle.dump(dataset_en, fp)\n",
    "with open(\"./hugg_preprocessed/dataset_fa\", \"wb\") as fp:\n",
    "    pickle.dump(dataset_fa, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60111342-4e8a-4cf4-ab59-aa168f55bfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('en_index.json',\"r\") as json_file:\n",
    "    data = json.load(json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
